{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import mutual_info_classif, SelectKBest, chi2\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of       user_lang  lang time_zone location verified  friends_count  \\\n",
      "81630       0.3  0.24      0.48     0.54        0      -0.089747   \n",
      "7201       0.24  0.24      0.48     0.46        0       0.043321   \n",
      "68170      0.24  0.12      0.52     0.54        0       0.124640   \n",
      "85236      0.18  0.15      0.48     0.46        0       0.612556   \n",
      "82466      0.18  0.15      0.52     0.54        0       0.346420   \n",
      "...         ...   ...       ...      ...      ...            ...   \n",
      "29321      0.24  0.19      0.48     0.54        0      -0.030606   \n",
      "18664       0.3   0.3      0.52     0.46        0       0.412954   \n",
      "7875       0.18   0.3      0.48     0.46        0       0.509059   \n",
      "40010      0.13  0.24      0.52     0.54        0      -0.082354   \n",
      "94809      0.13  0.12      0.48     0.54        0       0.095070   \n",
      "\n",
      "       compare_text source  favourites_count  listed_count  statuses_count  \\\n",
      "81630     -1.714341   0.03         -0.655589     -0.927414       -0.658560   \n",
      "7201       1.045725   0.07         -1.674391      1.004699       -1.688557   \n",
      "68170      0.031055   0.05          0.324767      0.360661        0.325862   \n",
      "85236      0.730569   0.03          0.959116      1.004699        0.963913   \n",
      "82466     -1.575490   0.05         -1.232270     -0.375382       -1.246478   \n",
      "...             ...    ...               ...           ...             ...   \n",
      "29321      0.471418    0.1          1.218622      1.280715        1.219133   \n",
      "18664     -0.196349   0.11          1.103286     -0.283377        1.109753   \n",
      "7875      -0.263411   0.07          0.401658      0.452667        0.398782   \n",
      "40010     -0.366055   0.07          1.045618      1.096704        1.045948   \n",
      "94809      0.213692   0.07          0.968727      1.004699        0.968470   \n",
      "\n",
      "       followers_count label  cred_score  eye_truth  hour  weekday  month  \\\n",
      "81630        -0.666672     0   -0.130189  -1.012993    13        3      8   \n",
      "7201         -1.677142     2   -0.130189  -0.954368    12        3      8   \n",
      "68170         0.319929     2   -0.130189   0.419595    13        3      8   \n",
      "85236         0.956446     1   -0.130189  -0.063721    13        3      8   \n",
      "82466        -1.239537    -1   -0.130189  -0.313076    13        3      8   \n",
      "...                ...   ...         ...        ...   ...      ...    ...   \n",
      "29321         1.211052     0   -0.130189  -1.208918    13        3      8   \n",
      "18664         1.099662     1   -2.733967  -1.556621    12        3      8   \n",
      "7875          0.391537     1   -0.130189  -0.913513    12        3      8   \n",
      "40010         1.036010     0   -0.130189  -0.453187    13        3      8   \n",
      "94809         0.956446     1   -0.130189   0.289248    13        3      8   \n",
      "\n",
      "       year  \n",
      "81630  2021  \n",
      "7201   2021  \n",
      "68170  2021  \n",
      "85236  2021  \n",
      "82466  2021  \n",
      "...     ...  \n",
      "29321  2021  \n",
      "18664  2021  \n",
      "7875   2021  \n",
      "40010  2021  \n",
      "94809  2021  \n",
      "\n",
      "[100 rows x 19 columns]>\n"
     ]
    }
   ],
   "source": [
    "# Load dataset using pandas\n",
    "df = pd.read_csv(\"test_data cs 1.csv\")\n",
    "pd.set_option('future.no_silent_downcasting', True)\n",
    "\n",
    "# Sample 1000 rows without replacement\n",
    "df = df.sample(n=100, replace=False, random_state=42)\n",
    "\n",
    "# Drop 'screen_name' 'text' (not useful for modeling)\n",
    "df = df.drop(columns=[\"screen_name\", \"text\"])\n",
    "\n",
    "# Encode 'verified' (target variable)\n",
    "df[\"verified\"] = df[\"verified\"].replace({\"f\": 0, \"t\": 1})\n",
    "\n",
    "# Convert 'created_at' to datetime format and extract features\n",
    "df[\"created_at\"] = pd.to_datetime(df[\"created_at\"], format=\"%a %b %d %H:%M:%S %Y\")\n",
    "df[\"hour\"] = df[\"created_at\"].dt.hour\n",
    "df[\"weekday\"] = df[\"created_at\"].dt.weekday\n",
    "df[\"month\"] = df[\"created_at\"].dt.month\n",
    "df[\"year\"] = df[\"created_at\"].dt.year\n",
    "df = df.drop(columns=[\"created_at\"])  # Drop raw datetime column\n",
    "\n",
    "# Frequency Encoding for categorical variables\n",
    "categorical_cols = [\"user_lang\", \"lang\", \"time_zone\", \"location\", \"source\"]\n",
    "for col in categorical_cols:\n",
    "    freq_map = df[col].value_counts(normalize=True).to_dict()\n",
    "    df[col] = df[col].replace(freq_map)\n",
    "\n",
    "# Ordinal Encoding for 'label' (eyewitness type)\n",
    "eyewitness_order = {\"don't know\": -1, \"non-eyewitness\": 0, \"indirect-eyewitness\": 1, \"direct-eyewitness\": 2}\n",
    "df[\"label\"] = df[\"label\"].replace(eyewitness_order)\n",
    "\n",
    "\n",
    "# Standardization of numerical features\n",
    "num_cols = [\"followers_count\", \"statuses_count\", \"friends_count\", \"favourites_count\",\n",
    "            \"listed_count\", \"cred_score\", \"eye_truth\", \"compare_text\"]\n",
    "scaler = StandardScaler()\n",
    "df[num_cols] = scaler.fit_transform(df[num_cols])\n",
    "\n",
    "# Print column names\n",
    "print(df.head)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train/test split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = df.drop(\"verified\", axis=1)\n",
    "y = df[\"verified\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=True, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GBC using all features of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of unknown and binary targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[117], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m gbc\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m      5\u001b[0m preds \u001b[38;5;241m=\u001b[39m gbc\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[1;32m----> 7\u001b[0m f1_score_all \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mround\u001b[39m(\u001b[43mf1_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maverage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweighted\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF1 Score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf1_score_all\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Python313\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:216\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    214\u001b[0m         )\n\u001b[0;32m    215\u001b[0m     ):\n\u001b[1;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    222\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    225\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    226\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1324\u001b[0m, in \u001b[0;36mf1_score\u001b[1;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1144\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[0;32m   1145\u001b[0m     {\n\u001b[0;32m   1146\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1171\u001b[0m     zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1172\u001b[0m ):\n\u001b[0;32m   1173\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute the F1 score, also known as balanced F-score or F-measure.\u001b[39;00m\n\u001b[0;32m   1174\u001b[0m \n\u001b[0;32m   1175\u001b[0m \u001b[38;5;124;03m    The F1 score can be interpreted as a harmonic mean of the precision and\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1322\u001b[0m \u001b[38;5;124;03m    array([0.66666667, 1.        , 0.66666667])\u001b[39;00m\n\u001b[0;32m   1323\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1324\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfbeta_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1325\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1326\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1327\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1328\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1330\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1331\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1332\u001b[0m \u001b[43m        \u001b[49m\u001b[43mzero_division\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mzero_division\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1333\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python313\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:189\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    187\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[1;32m--> 189\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    191\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[0;32m    193\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1517\u001b[0m, in \u001b[0;36mfbeta_score\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1336\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[0;32m   1337\u001b[0m     {\n\u001b[0;32m   1338\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1365\u001b[0m     zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1366\u001b[0m ):\n\u001b[0;32m   1367\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute the F-beta score.\u001b[39;00m\n\u001b[0;32m   1368\u001b[0m \n\u001b[0;32m   1369\u001b[0m \u001b[38;5;124;03m    The F-beta score is the weighted harmonic mean of precision and recall,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1514\u001b[0m \u001b[38;5;124;03m    0.12...\u001b[39;00m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1517\u001b[0m     _, _, f, _ \u001b[38;5;241m=\u001b[39m \u001b[43mprecision_recall_fscore_support\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1518\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1519\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1520\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1521\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1523\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1524\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwarn_for\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mf-score\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1525\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1526\u001b[0m \u001b[43m        \u001b[49m\u001b[43mzero_division\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mzero_division\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1527\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1528\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f\n",
      "File \u001b[1;32mc:\\Python313\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:189\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    187\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[1;32m--> 189\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    191\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[0;32m    193\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1830\u001b[0m, in \u001b[0;36mprecision_recall_fscore_support\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1661\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute precision, recall, F-measure and support for each class.\u001b[39;00m\n\u001b[0;32m   1662\u001b[0m \n\u001b[0;32m   1663\u001b[0m \u001b[38;5;124;03mThe precision is the ratio ``tp / (tp + fp)`` where ``tp`` is the number of\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1827\u001b[0m \u001b[38;5;124;03m array([2, 2, 2]))\u001b[39;00m\n\u001b[0;32m   1828\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1829\u001b[0m _check_zero_division(zero_division)\n\u001b[1;32m-> 1830\u001b[0m labels \u001b[38;5;241m=\u001b[39m \u001b[43m_check_set_wise_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1832\u001b[0m \u001b[38;5;66;03m# Calculate tp_sum, pred_sum, true_sum ###\u001b[39;00m\n\u001b[0;32m   1833\u001b[0m samplewise \u001b[38;5;241m=\u001b[39m average \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msamples\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1596\u001b[0m, in \u001b[0;36m_check_set_wise_labels\u001b[1;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[0;32m   1593\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maverage has to be one of \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(average_options))\n\u001b[0;32m   1595\u001b[0m y_true, y_pred \u001b[38;5;241m=\u001b[39m attach_unique(y_true, y_pred)\n\u001b[1;32m-> 1596\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1597\u001b[0m \u001b[38;5;66;03m# Convert to Python primitive type to avoid NumPy type / Python str\u001b[39;00m\n\u001b[0;32m   1598\u001b[0m \u001b[38;5;66;03m# comparison. See https://github.com/numpy/numpy/issues/6784\u001b[39;00m\n\u001b[0;32m   1599\u001b[0m present_labels \u001b[38;5;241m=\u001b[39m _tolist(unique_labels(y_true, y_pred))\n",
      "File \u001b[1;32mc:\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:107\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m    104\u001b[0m     y_type \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y_type) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 107\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    108\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassification metrics can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt handle a mix of \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m targets\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    109\u001b[0m             type_true, type_pred\n\u001b[0;32m    110\u001b[0m         )\n\u001b[0;32m    111\u001b[0m     )\n\u001b[0;32m    113\u001b[0m \u001b[38;5;66;03m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[0;32m    114\u001b[0m y_type \u001b[38;5;241m=\u001b[39m y_type\u001b[38;5;241m.\u001b[39mpop()\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of unknown and binary targets"
     ]
    }
   ],
   "source": [
    "gbc = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "gbc.fit(X_train, y_train)\n",
    "preds = gbc.predict(X_test)\n",
    "\n",
    "f1_score_all = round(f1_score(y_test, preds, average='weighted'), 3)\n",
    "print(f\"F1 Score: {f1_score_all}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    user_lang   lang time_zone location source label  hour  weekday  month  \\\n",
      "548     0.216  0.202      0.49    0.436  0.053     0    12        4      8   \n",
      "652     0.193   0.31      0.51    0.436  0.036    -1    13        4      8   \n",
      "43      0.181  0.102      0.51    0.436  0.047    -1    13        4      8   \n",
      "48      0.193   0.31      0.49    0.564  0.054    -1    13        4      8   \n",
      "701     0.216  0.102      0.51    0.564  0.054     1    13        4      8   \n",
      "..        ...    ...       ...      ...    ...   ...   ...      ...    ...   \n",
      "902     0.193  0.128      0.49    0.436  0.056     0    13        4      8   \n",
      "938     0.193  0.202      0.49    0.564  0.056    -1    13        4      8   \n",
      "538     0.181  0.258      0.49    0.564  0.053     1    12        4      8   \n",
      "111     0.181  0.128      0.51    0.564  0.056    -1    13        4      8   \n",
      "806     0.216  0.258      0.51    0.436  0.056    -1    13        4      8   \n",
      "\n",
      "     year  ...  zo8eoi3qjs9s  zxcbwxq9tn  followers_count  statuses_count  \\\n",
      "548  2021  ...           0.0         0.0        -0.017217        0.009737   \n",
      "652  2021  ...           0.0         0.0         0.178192        0.119685   \n",
      "43   2021  ...           0.0         0.0        -0.086388       -0.030652   \n",
      "48   2021  ...           0.0         0.0        -0.076012       -0.024481   \n",
      "701  2021  ...           0.0         0.0        -0.290443       -0.147893   \n",
      "..    ...  ...           ...         ...              ...             ...   \n",
      "902  2021  ...           0.0         0.0        -0.003382        0.017591   \n",
      "938  2021  ...           0.0         0.0        -0.456453       -0.242695   \n",
      "538  2021  ...           0.0         0.0        -0.081200       -0.027286   \n",
      "111  2021  ...           0.0         0.0         0.364954        0.226829   \n",
      "806  2021  ...           0.0         0.0        -0.295630       -0.150698   \n",
      "\n",
      "     friends_count  favourites_count  listed_count  cred_score  eye_truth  \\\n",
      "548      -0.038316         -0.030899     -0.405654   -0.061398  -0.687653   \n",
      "652       0.265280          0.205912     -0.042409   -0.061398   1.163320   \n",
      "43        0.239980         -0.114035     -0.768899    2.300063   1.581040   \n",
      "48       -0.266013         -0.101438     -0.678087   -0.061398  -1.198863   \n",
      "701       0.062882         -0.360923     -1.677011   -0.061398  -0.014595   \n",
      "..             ...               ...           ...         ...        ...   \n",
      "902      -0.569610         -0.013264     -0.314843   -2.422859   0.562240   \n",
      "938      -0.152165         -0.557425     -0.678087    2.300063   2.756252   \n",
      "538       0.442378         -0.106477     -0.133220   -2.422859  -0.654013   \n",
      "111       0.657425          0.432646      1.773816   -0.061398   0.828890   \n",
      "806       0.897772         -0.365961      1.683005   -0.061398  -0.234669   \n",
      "\n",
      "     compare_text  \n",
      "548      0.158970  \n",
      "652     -0.617492  \n",
      "43       0.399398  \n",
      "48      -0.080952  \n",
      "701      0.649346  \n",
      "..            ...  \n",
      "902     -0.883277  \n",
      "938      1.125400  \n",
      "538      0.521213  \n",
      "111     -0.162162  \n",
      "806      0.560807  \n",
      "\n",
      "[700 rows x 518 columns]\n"
     ]
    }
   ],
   "source": [
    "X_train_V = X_train.copy()\n",
    "print(X_train_V)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
